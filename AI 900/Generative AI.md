## Generative AI

---

## GENERATIVE AI CAPABILITIES

- Natural Language Generation  
- Image Generation  

---

## LANGUAGE MODELS

- **Transformer Models**
  - encoder
  - decoder
- Tokenization
- Embeddings
- Attention  

Attention is a technique used to examine a sequence of text tokens and try to quantify the strength of the relationships between them. In particular, self-attention involves considering how other tokens around one particular token influence that token's meaning.

---

## LARGE LANGUAGE MODELS (LLMs) vs SMALL LANGUAGE MODELS (SLMs)

| Large Language Models (LLMs) | Small Language Models (SLMs) |
|-----------------------------|------------------------------|
| LLMs are trained with vast quantities of text that represents a wide range of general subject matter – typically by sourcing data from the Internet and other generally available publications. | SLMs are trained with smaller, more subject-focused datasets |
| When trained, LLMs have many billions (even trillions) of parameters (weights that can be applied to vector embeddings to calculate predicted token sequences). | Typically have fewer parameters than LLMs. |
| Able to exhibit comprehensive language generation capabilities in a wide range of conversational contexts. | This focused vocabulary makes them very effective in specific conversational topics, but less effective at more general language generation. |
| Their large size can impact their performance and make them difficult to deploy locally on devices and computers. | The smaller size of SLMs can provide more options for deployment, including local deployment to devices and on-premises computers; and makes them faster and easier to fine-tune. |
| Fine-tuning the model with additional data to customize its subject expertise can be time-consuming, and expensive in terms of the compute power required to perform the additional training. | Fine-tuning can potentially be less time-consuming and expensive. |

---

## LEVELS OF COPILOT ADOPTION

- **off-the-shelf use**  
  Microsoft Copilot for Microsoft 365 to empower users and increase their productivity.

- **extending Microsoft Copilot**  
  To support custom business processes or tasks, using your own data to control how Copilot responds to user prompts in your organization.

- **custom development**  
  To integrate generative AI into business apps or to create unique experiences for your customers.

---

## COPILOT PROMPTS

1. Start with a specific goal for what you want the copilot to do  
2. Provide a source to ground the response in a specific scope of information  
3. Add context to maximize response appropriateness and relevance  
4. Set clear expectations for the response  
5. Iterate based on previous prompts and responses to refine the result  

---

## DEVELOP COPILOTS

- Copilot Studio  
- Azure AI Studio  

---

## AZURE AI STUDIO

- The model catalog and prompt flow development capabilities of Azure Machine Learning service.
- The generative AI model deployment, testing, and custom data integration capabilities of Azure OpenAI service.
- Integration with Azure AI Services for speech, vision, language, document intelligence, and content safety.

---

## RETRIEVAL AUGMENTED GENERATION (RAG)

---

## AZURE AI HUB

- Create and manage AI projects  
- Develop generative AI apps  
- Explore available AI models  
- Leverage RAG  
- Monitor and evaluate AI models  
- Integrate with Azure services  
- Build responsibly  

---

## RESPONSIBLE GENERATIVE AI

- Identify potential harms that are relevant to your planned solution.
- Measure the presence of these harms in the outputs generated by your solution.
- Mitigate the harms at multiple layers in your solution to minimize their presence and impact, and ensure transparent communication about potential risks to users.
- Operate the solution responsibly by defining and following a deployment and operational readiness plan.

- Identify potential harms → NIST AI Risk Management  
- Prioritize identified harms  
- Test and verify the prioritized harms  
- Document and share the verified harms  

Red teaming is a strategy that is often used to find security vulnerabilities or other weaknesses that can compromise the integrity of a software solution.

---

## MITIGATE POTENTIAL HARM

1. Model  
2. Safety System  
3. Metaprompt and grounding  
4. User experience  

---

=====================================================================

Generative AI models offer the capability of generating images based on a prompt by using DALL-E models, such as generating images from natural language. The other AI capabilities are used in different contexts to achieve other goals.

System messages should be used to set the context for the model by describing expectations. Based on system messages, the model knows how to respond to prompts.

Embeddings is an Azure OpenAI model that converts text into numerical vectors for analysis. Embeddings can be used to search, classify, and compare sources of text for similarity.

Copilots are often integrated into applications to provide a way for users to get help with common tasks from a generative AI model. Copilots are based on a common architecture, so developers can build custom copilots for various business-specific applications and services.

The safety system layer includes platform-level configurations and capabilities that help mitigate harm. For example, the Azure OpenAI service includes support for content filters that apply criteria to suppress prompts and responses based on the classification of content into four severity levels (safe, low, medium, and high) for four categories of potential harm (hate, sexual, violence, and self-harm).

DALL-E has image editing, image generation, and image variation skills.  
DALL-E is a model that can generate images from natural language.  
GPT-4 and GPT-3.5 can understand and generate natural language and code but not images.  
Embeddings can convert text into numerical vector form to facilitate text similarity.  
Whisper can transcribe and translate speech to text.

---
